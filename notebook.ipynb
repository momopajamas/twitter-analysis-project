{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2687fb5-e50c-4251-b9ed-9dec0f15b93b",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02274cc-a946-44ad-a54f-ae69201f6a23",
   "metadata": {},
   "source": [
    "Our company wants wants to be able to factor in sentiments about our products that are expressed on social media platforms, namely X (formerly Twitter), where millions of users share positive, negative, or neutral sentiments about products they use in an organic way. While consumer or user reviews left through official platforms such as Yelp or Amazon are important to consider, the pool of users is rather limited as not everyone will go the extra mile to provide a review through those \"official\" channels, and taking more organic feedback expressed through platforms like X into consideration can provide us an extra layer of insight as to how the public is interacting with and perceiving our products.\n",
    "\n",
    "The way we will go about this, is to create a model that is trained and tested on a dataset containing tweets where users expressed various emotions or reactions to other products, as the essential issue is how well our model is able to parse through and categorize expressed sentiments.\n",
    "\n",
    "While many tweets will fall easily under either Positive or Negative categories, we also need to be able to handle more neutral sentiments expressed. In other words, our model will need to address the following questions:\n",
    "\n",
    "1. How well can we differentiate between Positive and Negative sentiments?\n",
    "2. How successful is our model at engaging Neutral sentiments?\n",
    "\n",
    "For our purposes, both Positive and Negative sentiments would be equally important in different ways, as we need to rely on Positive sentiments in order to ascertain which aspects of our products are well-received by customers and why that is so, while Negative sentiments can call our attention to aspects of our products that turn customers away from our products. \n",
    "\n",
    "By relying on both Negative and Positive sentiments, we can better understand which changes need to be made, and which aspects of our products should be developed further. In other words, **neither False Positives nor False Negatives are inherently more important for us**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb5bc9-31ed-4984-ae40-35746a6c927c",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e030c3-97d1-412e-aaf3-6420536c81c4",
   "metadata": {},
   "source": [
    "As this problem is about analyzing and categorizing sentiments expressed through text, we will need to build a model capable of Natural Language Processing, or NLP for short. This model needs to be adept at processing and parsing through text, and categorizing the text as 'Positive', 'Negative', or Neutral'.\n",
    "\n",
    "We will engage in NLP to build first a binary classifier that is capable of differentiating between 'Positive' and 'Negative' sentiments, and then we will expand this model into a multi-class classifier by computing the 'Neutral' sentiments. \n",
    "\n",
    "### Dataset\n",
    "For these purposes, we will work with a [dataset we retrieved from data.world](https://data.world/crowdflower/brands-and-product-emotions) that contains more than 9,000 tweets expressing Positive, Negative, or Neutral sentiments towards Apple or Google products.\n",
    "\n",
    "The dataset contains information across three columns:\n",
    "1. `tweets_text`, which contains the text of the collected tweets themselves.\n",
    "2. `emotion_in_tweet_is_directed_at`, which indicates which product the tweet is speaking to. This column contains a number of values, however they all fall under either Apple of Google products (with the exception of a number of rows that contain 'No data').\n",
    "3. `is_there_an_emotion_directed_at_a_brand_or_product`, which categorizes the collected tweets according to either 'Positive emotion', 'Negative emotion', or 'No emotion toward brand or product'. There is a fourth category, 'I can't tell', which we need to investigate more before deciding whether or not to remove these entries.\n",
    "\n",
    "### Features and Labels\n",
    "The `tweets_text` column will serve as our features, or X, while `is_there_an_emotion_directed_at_a_brand_or_product` will serve as our labels, or y. \n",
    "\n",
    "To be more specific, we will use the `tweets_text` column to generate **TF-IDF (Term Frequency-Inverse Document Frequency)** scores, which assigns numeric values for key terms by weighing their frequency within a certain text against their frequency across different texts. This will help our model in gaining signals from significant words and reduce noise from frequent, insignificant words. These will be our features, at least in the initial baseline model.\n",
    "\n",
    "The second column, `emotion_in_tweet_is_directed_at`, is not relevant for our purposes, as our task is to build a model that can categorize the sentiments expressed, and not to determine *who* the sentiments are addressing.\n",
    "\n",
    "### Class Imbalance\n",
    "Our labels have significant class imbalance, with Negative sentiments only comprising 6% of the data compared to 33% for Positive and 59% for Neutral. This will cause issues for us in both training the model and evaluating its performance according to success metrics.\n",
    "\n",
    "To compensate for this imbalance we will deploy two strategies:\n",
    "1. **Data Augmentation**, which essentially gives our model more examples of the minority class to learn from by synthetically creating entries for the minority class through techniques such as 'back-translation' or 'synonym replacement.'\n",
    "2. **Class Weighting**, which is a strategy that can be used with certain models that gives higher importance to minority classes. \n",
    "\n",
    "### Success Metrics\n",
    "As described above, we need to rely on both Positive and Negative sentiments equally as they both convey insights about our products in different ways and provide different signals as to which changes need to be made in the future.\n",
    "\n",
    "For this reason, we will rely on the two following variations of the **F1-Score**, which balances both False Negatives and False Positives since neither is inherently more important for us:\n",
    "1. **Macro F1-Score**, since this is a multi-class classification task and not binary.\n",
    "2. **Weighted F1-Score**, which accounts for any remaining class imbalance after we deploy the imbalance compensation strategies listed above.\n",
    "\n",
    "### Model Selection\n",
    "We will start with a simple baseline model as an initial performance check before moving on to more complex models. Since we have a relatively large dataset and significant class imbalance, we will deploy **Logistic Regression**, which can help compensate for this imbalance using a weighted approach. This model can also help us determine relative imporance of features, which we can then use in tuning later complex models. \n",
    "\n",
    "Logistic Regression will require us to compute **TF-IDF (Term Frequency-Inverse Document Frequency)**, as described above. However, this will have limited applicability on future application of the model, as future tweets will undoubtedly contain new slang and terms that arise and will not be computed in this current model.\n",
    "\n",
    "After establishing a baseline, we will then move on to testing out more complex models, namely **BERTweet (Bidirectional Encoder Representations from Transformers)**, a Deep Learning model which is well-suited for analyzing tweets in particular as it is trained on 850 million English tweets and can process special characters such as emojies, hashtags, etc., and is capable of determining contextual meaning from limited text as tweets had a limit of 140 characters back in 2013, which is when our dataset was compiled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efe8e8-ab0d-4f00-8798-2eaba8b4cebc",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89eddf1-3638-4ebe-ae5f-9d1aa36402e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d1bd21-842c-48e2-bbf1-2439879dc5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4633dedf-c980-488e-9069-c43250aac75b",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192091fc-324a-421a-b17b-e27fbbef6c41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ded5c-3ace-40b0-9902-08e56f9d8ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0a9192e-5c04-4be1-88ea-0b955cb62d5b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a17859-b31c-4a11-b3ff-2925c41a8714",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65f8b1c2-2a02-40a8-8056-1eb6b54c66eb",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea12da3-8779-42fb-90af-071f28988c8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad3891c-86d8-413d-9ea8-3ffdaf56d745",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fc5d5-0254-4b68-bf14-bdae45eb8434",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6b276cb-d6d6-428f-ae78-4b69a2342d20",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf3ac8-cce6-4b68-a399-0de398b07465",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7983e4-4edd-4161-88e6-ba54d2d18d35",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
