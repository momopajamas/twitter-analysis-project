{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2687fb5-e50c-4251-b9ed-9dec0f15b93b",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02274cc-a946-44ad-a54f-ae69201f6a23",
   "metadata": {},
   "source": [
    "Our company, Microsoft, wants to be able to factor in sentiments about our products that are expressed on social media platforms, namely X (formerly Twitter), where millions of users share positive, negative, or neutral sentiments about products they use in an organic way. While consumer or user reviews left through official platforms such as Yelp or Amazon are important to consider, the pool of users is rather limited as not everyone will go the extra mile to provide a review through those \"official\" channels, and taking more organic feedback expressed through platforms like X into consideration can provide us an extra layer of insight as to how the public is interacting with and perceiving our products. \n",
    "\n",
    "Specifically, Microsoft wants to be able to filter tweets carrying Positive sentiments towards our products or services so that we are able to assess what's working well and what areas can and should be developed further.\n",
    "\n",
    "The way we will go about this, is to create a **binary classifier model** that is trained and tested on a dataset containing tweets where users expressed various emotions or reactions to other products, as the essential issue is how well our model is able to parse through and differentiate between Positive tweets on the one hand, and Negative or Neutral tweets on the other hand.\n",
    "\n",
    "In evaluating the efficacy of our model, we need to ascertain how effective the model was at correctly identifying Positive tweets. Put differently, we need to keep an eye out for **False Positives**, since our model would cause many issues for us if it incorrectly pulled in Negative or Neutral tweets, which would complicate or muddy our analysis. While False Negatives are also something to consider, they are of less importance as missing out on Positive tweets would be less damaging to us as it is generally better to avoid overestimating Positive feedback anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb5bc9-31ed-4984-ae40-35746a6c927c",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e030c3-97d1-412e-aaf3-6420536c81c4",
   "metadata": {},
   "source": [
    "As this problem is about analyzing and categorizing sentiments expressed through text, we will need to build a model capable of Natural Language Processing, or NLP for short. This model needs to be adept at processing and parsing through text, and categorizing the text as 'Positive', 'Not Positive' (ie: 'Negative' or 'Neutral').\n",
    "\n",
    "We will engage in NLP to build a binary classifier that is capable of differentiating between 'Positive' and 'Negative' or 'Neutral' sentiments.\n",
    "\n",
    "### Dataset\n",
    "For these purposes, we will work with a [dataset we retrieved from data.world](https://data.world/crowdflower/brands-and-product-emotions) that contains more than 9,000 tweets expressing Positive, Negative, or Neutral sentiments towards Apple or Google products.\n",
    "\n",
    "The dataset contains information across three columns:\n",
    "1. `tweets_text`, which contains the text of the collected tweets themselves.\n",
    "2. `emotion_in_tweet_is_directed_at`, which indicates which product the tweet is speaking to. This column contains a number of values, however they all fall under either Apple of Google products (with the exception of a number of rows that contain 'No data').\n",
    "3. `is_there_an_emotion_directed_at_a_brand_or_product`, which categorizes the collected tweets according to either 'Positive emotion', 'Negative emotion', or 'No emotion toward brand or product'. There is a fourth category, 'I can't tell', which we need to investigate more before deciding whether or not to remove these entries.\n",
    "\n",
    "### Features and Labels\n",
    "The `tweets_text` column will serve as our features, or X, while `is_there_an_emotion_directed_at_a_brand_or_product` will serve as our labels, or y. \n",
    "\n",
    "To be more specific, we will use the `tweets_text` column to generate **TF-IDF (Term Frequency-Inverse Document Frequency)** scores, which assigns numeric values for key terms by weighing their frequency within a certain text against their frequency across different texts. This will help our model in gaining signals from significant words and reduce noise from frequent, insignificant words. These will be our features, at least in the initial baseline model.\n",
    "\n",
    "The second column, `emotion_in_tweet_is_directed_at`, is not relevant for our purposes, as our task is to build a model that can categorize the sentiments expressed, and not to determine *whom* the sentiments are addressing.\n",
    "\n",
    "### Class Imbalance\n",
    "Our labels have significant class imbalance, with Negative sentiments only comprising 6% of the data compared to 33% for Positive and 59% for Neutral. Since we are adding the Negative and Neutral tweets together in a single class, this gives us:\n",
    "- 33% Positive\n",
    "- 65% Not Positive\n",
    "  \n",
    "This will cause issues for us in both training the model and evaluating its performance according to success metrics.\n",
    "\n",
    "To compensate for this imbalance we will deploy **Class Weighting**, which is a strategy that can be used with certain models that gives higher importance to minority classes. \n",
    "\n",
    "### Success Metrics\n",
    "As described above, we need to pay extra mind to our model's ability to correctly identify Positive tweets, placing a higher importance on the rates of False Positives. However, we should also keep an eye on False Negatives to minimize the number of Positive tweets falling through the cracks.\n",
    "\n",
    "For this reason, we will rely on the following metrics:\n",
    "1. **Precision Score**, which evaluates how accurate we were in actually identifying Positive tweets (telling us the rates of False Positives). The higher the precision score, the lower the rate of False Positives. This will be our primary metric.\n",
    "2. **F1-Score**, which weighs the rate of False Positives and False Negatives, since we also want to minimize the rate at which we misclassify Positive tweets as Not Positive. This will be a seconadry metric for us.\n",
    "\n",
    "### Model Selection\n",
    "We will start with a simple baseline model as an initial performance check before moving on to more complex models. Since we have some class imbalance, we will deploy **Multinomial Naive Bayes (Multinomial NB)**, which can help compensate for this imbalance using a weighted approach. This model is also better at producing the metrics we outlined above. \n",
    "\n",
    "Multinomial NB will require us to compute **TF-IDF (Term Frequency-Inverse Document Frequency)**, as described above. However, this will have limited applicability on future application of the model, as future tweets will undoubtedly contain new slang and terms that arise and will not be computed in this current model.\n",
    "\n",
    "After establishing a baseline, we will then move on to testing out more complex models, namely **BERTweet (Bidirectional Encoder Representations from Transformers)**, a Deep Learning model which is well-suited for analyzing tweets in particular as it is trained on 850 million English tweets and can process special characters such as emojies, hashtags, etc., and is capable of determining contextual meaning from limited text as tweets had a limit of 140 characters back in 2013, which is when our dataset was compiled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efe8e8-ab0d-4f00-8798-2eaba8b4cebc",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89eddf1-3638-4ebe-ae5f-9d1aa36402e2",
   "metadata": {},
   "source": [
    "Since we want to first run a baseline MultinomialNB model, we will need to carry out several steps of Data Preparation in order for the data to be ready for modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10d1bd21-842c-48e2-bbf1-2439879dc5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "367e01e6-71fd-4fce-9d36-e29091832a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "# specifying the encoding as the file is a non-UTF-8 CSV file\n",
    "\n",
    "df = pd.read_csv(\"data/judge_tweet_product.csv\", encoding=\"latin-1\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac43546-a547-48d3-9d24-c53851c3ef04",
   "metadata": {},
   "source": [
    "As discussed earlier, the `emotion_in_tweet_is_directed_at` column is not necessary for our purposes of determining the sentiment of the tweet, so we will drop it from our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e7157d-b4a2-41b9-be0e-18a406b02386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the second column\n",
    "\n",
    "df = df.drop('emotion_in_tweet_is_directed_at', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c9a182-149c-4eb9-810d-00793708b9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if dropping column worked\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701163e-c760-4243-8806-8a4c89089b70",
   "metadata": {},
   "source": [
    "#### Now we need to check for any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c8c93a-3f98-4c2c-b93d-62c3e5f23f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                            1\n",
       "is_there_an_emotion_directed_at_a_brand_or_product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17aaf5d-fb97-4bf9-8c7f-1188b4ef1750",
   "metadata": {},
   "source": [
    "We have one row with null values. Let's take a look to see if we're able to simply drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ac85ca-5da7-45bd-b883-4271eefdf049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_text is_there_an_emotion_directed_at_a_brand_or_product\n",
       "6        NaN                 No emotion toward brand or product"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1999057-0ac3-4bc7-893c-6bc6b97b0a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                            0\n",
       "is_there_an_emotion_directed_at_a_brand_or_product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the row with null value\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# making sure it worked\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d13b2c-9c4a-47f1-834f-272dd204a6c7",
   "metadata": {},
   "source": [
    "#### Cleaning Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df21a52-60e1-4ec4-b815-5f8c217b0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02712e63-f200-437d-a2b8-66364c62ad91",
   "metadata": {},
   "source": [
    "There is a fourth category in our Target column, **'I can't tell'**, indicating that those who gathered this dataset were unsure about the sentiment expressed in about 2% of the tweets. \n",
    "\n",
    "Let's take a quick look. Since they only make up 2% of the dataset, it may be best to simply drop these entries and focus on our analysis on the Positive, Negative, and Neutral categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c2215a6-6bf8-4995-b51a-e2592d5c445a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Thanks to @mention for publishing the news of ...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ÛÏ@mention &amp;quot;Apple has opened a pop-up st...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Just what America needs. RT @mention Google to...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>The queue at the Apple Store in Austin is FOUR...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Hope it's better than wave RT @mention Buzz is...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020</th>\n",
       "      <td>It's funny watching a room full of people hold...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9032</th>\n",
       "      <td>@mention yeah, we have @mention , Google has n...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9037</th>\n",
       "      <td>@mention Yes, the Google presentation was not ...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>&amp;quot;Do you know what Apple is really good at...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9066</th>\n",
       "      <td>How much you want to bet Apple is disproportio...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "90    Thanks to @mention for publishing the news of ...   \n",
       "102   ÛÏ@mention &quot;Apple has opened a pop-up st...   \n",
       "237   Just what America needs. RT @mention Google to...   \n",
       "341   The queue at the Apple Store in Austin is FOUR...   \n",
       "368   Hope it's better than wave RT @mention Buzz is...   \n",
       "...                                                 ...   \n",
       "9020  It's funny watching a room full of people hold...   \n",
       "9032  @mention yeah, we have @mention , Google has n...   \n",
       "9037  @mention Yes, the Google presentation was not ...   \n",
       "9058  &quot;Do you know what Apple is really good at...   \n",
       "9066  How much you want to bet Apple is disproportio...   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "90                                         I can't tell  \n",
       "102                                        I can't tell  \n",
       "237                                        I can't tell  \n",
       "341                                        I can't tell  \n",
       "368                                        I can't tell  \n",
       "...                                                 ...  \n",
       "9020                                       I can't tell  \n",
       "9032                                       I can't tell  \n",
       "9037                                       I can't tell  \n",
       "9058                                       I can't tell  \n",
       "9066                                       I can't tell  \n",
       "\n",
       "[156 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['is_there_an_emotion_directed_at_a_brand_or_product'] == \"I can't tell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb7f618-25e9-4abd-909a-45450bcb094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing \"I can't tell\" entries in the Target column from the dataframe\n",
    "\n",
    "df_clean = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] != \"I can't tell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db0243b-dc5e-4e16-bbf1-b0fb7c1bd66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8936 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[8936 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3825e565-9230-421f-8a9b-ba2bae883ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if it worked\n",
    "\n",
    "df_clean['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1982ad10-5b10-496e-8ec5-854c41d93675",
   "metadata": {},
   "source": [
    "Since our Target column contains three categories (\"Positive emotion, \"Negative emotion\", \"No emotion toward brand or product\"), and we'll need to collapse the latter two labels into a single category in order for us to conduct binary classification.\n",
    "\n",
    "We'll do this by converting the label values into 1s and 0s.\n",
    "- `1` meaning Positive\n",
    "- `0` meaning Not Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b8341d3-2cfa-4e3d-acf4-655f26b5b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping 1s and 0s onto the Target column values\n",
    "\n",
    "df_clean.loc[:,'is_there_an_emotion_directed_at_a_brand_or_product'] = df['is_there_an_emotion_directed_at_a_brand_or_product'].map({\n",
    "    'Positive emotion': 1,\n",
    "    'Negative emotion': 0,\n",
    "    'No emotion toward brand or product': 0\n",
    "})\n",
    "\n",
    "# converting binary values into integers\n",
    "\n",
    "df_clean.loc[:,'is_there_an_emotion_directed_at_a_brand_or_product'] = \\\n",
    "df_clean['is_there_an_emotion_directed_at_a_brand_or_product'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6440953-d1d4-4041-ad00-d4a29ffab5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure it worked\n",
    "\n",
    "df_clean['is_there_an_emotion_directed_at_a_brand_or_product'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a017a6-4e8b-4b75-81b5-a185a18903fe",
   "metadata": {},
   "source": [
    "For convenience, we'll change the name of our Target column to something shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03378338-96fc-441e-868f-ba47b45c5f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text is_positive\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...           0\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...           1\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...           1\n",
       "3  @sxsw I hope this year's festival isn't as cra...           0\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...           1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df_clean.rename(columns={'is_there_an_emotion_directed_at_a_brand_or_product': 'is_positive'})\n",
    "\n",
    "# checking if it worked\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee337b-2385-4021-92be-5145e0feea93",
   "metadata": {},
   "source": [
    "#### Train-Test-Splitting\n",
    "Now that our dataset is cleaned, we'll split the data into training and test sets before preprocessing the text data in order to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fd8a2c7-ac4b-45c5-894f-3886395ff72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting X (Features) and y (Target)\n",
    "\n",
    "X = df_clean[['tweet_text']]\n",
    "y = df_clean['is_positive'].astype(int)\n",
    "\n",
    "# splitting the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "982f77eb-1efb-4f91-98b5-0b0a72b046f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training sets into training and validation sets\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f31c2b8-8677-4012-98e5-23c945c4bb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0       0\n",
       "1       1\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "9088    1\n",
       "9089    0\n",
       "9090    0\n",
       "9091    0\n",
       "9092    0\n",
       "Name: is_positive, Length: 8936, dtype: int64>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba307d0-f56e-4771-98ec-068e9fc93118",
   "metadata": {},
   "source": [
    "#### Creating Custom Transformers and Pipelines\n",
    "##### **Baseline Model**\n",
    "\n",
    "We can now start preparing our X variable (features) for our modeling.\n",
    "\n",
    "We'll need to convert all words to lowercase, remove special characters, remove stop words, tokenize the text and apply lemmatization in order for our text to be processed uniformly across all variations of the same words.\n",
    "\n",
    "These steps can be built into our Pipeline, which we will deploy to prevent data leakage.\n",
    "\n",
    "First, we need to create a **custom transformer** to carry out these steps, before creating the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "248c59e1-f37c-493d-9e2c-1e4e969d5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining custom transformer with parameters that allow it to work like an sklearn transformer inside the pipelines\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This custom transformer will\n",
    "    1) Lower case the text,\n",
    "    2) Remove special characters,\n",
    "    3) Tokenize the text,\n",
    "    4) Lemmatize the text\n",
    "    \"\"\"\n",
    "    # initializing Lemmatizer for later use\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # fitting the transformer\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    # transforming the text, creating list to store preprocessed words\n",
    "    def transform(self, X):\n",
    "        preprocessed_words = []\n",
    "\n",
    "        # for loop to transform all words in the text\n",
    "        for word in X:\n",
    "            \n",
    "            word = word.lower() # lowercasing the words\n",
    "            \n",
    "            word = re.sub(r'[^a-z\\s]', '', word) # removing special characters\n",
    "            \n",
    "            tokens = nltk.word_tokenize(word) # tokenizing words\n",
    "            \n",
    "            lemmatized_words = ' '.join([self.lemmatizer.lemmatize(word) for word in tokens]) # lemmatizing the tokens \\\n",
    "                                                                                              # into a list of strings\n",
    "            \n",
    "            preprocessed_words.append(lemmatized_words) # adding preprocessed words back to the list\n",
    "            \n",
    "        return preprocessed_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c9669-72dc-414c-b86d-8abc72ffd7ec",
   "metadata": {},
   "source": [
    "Now that we have our custom function ready, we can prepare a Pipeline for our baseline MultinomialNB model. \n",
    "\n",
    "This Pipeline will cover the following steps:\n",
    "1. Run the Custom Transformer we just created.\n",
    "2. Vectorize the text into TF-IDF features.\n",
    "3. Run a MultinomialNB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c35d616-e0ac-4145-805c-716b9b0e908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Pipeline for MultinomialNB modeling\n",
    "\n",
    "baseline_pipe = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()), # preprocessing transformer\n",
    "    ('vectorizer', TfidfVectorizer()), # Convert to TF-IDF features\n",
    "    ('classifier', MultinomialNB(class_prior=[0.67, 0.33])), # Run the MultinomialNB model, adjusted for minority class\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183cb440-5d95-49af-ab15-425738500d5c",
   "metadata": {},
   "source": [
    "##### **Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "835045cd-d0ef-4ee9-826d-854739b85e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression(\n",
    "        max_iter=1000, # increasing iterations to capture data complexity\n",
    "        class_weight='balanced' # balancing in favor of minority class\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99939b5-e30b-4e87-aa45-2f7807d94393",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4633dedf-c980-488e-9069-c43250aac75b",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "With our two pipelines prepared, we can proceed with modeling.\n",
    "\n",
    "First we will need to train the models on our training data and evaluate their performance using the metrics we outlined above (Precision and F1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "deb584cb-ea50-4ce1-bae0-11c745da7728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Precision: 0.8208955223880597\n",
      "Baseline Recall: 0.12008733624454149\n",
      "Baseline F1: 0.20952380952380953\n"
     ]
    }
   ],
   "source": [
    "# fitting and running baseline model (MultinomialNB)\n",
    "baseline_pipe.fit(X_train['tweet_text'], y_train)\n",
    "\n",
    "# predicting validation set\n",
    "y_val_pred_baseline = baseline_pipe.predict(X_val['tweet_text'])\n",
    "\n",
    "# evaluating baseline model\n",
    "baseline_precision = precision_score(y_val, y_val_pred_baseline)\n",
    "baseline_recall = recall_score(y_val, y_val_pred_baseline)\n",
    "baseline_f1 = f1_score(y_val, y_val_pred_baseline)\n",
    "\n",
    "print(f'Baseline Precision: {baseline_precision}')\n",
    "print(f'Baseline Recall: {baseline_recall}')\n",
    "print(f'Baseline F1: {baseline_f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192091fc-324a-421a-b17b-e27fbbef6c41",
   "metadata": {},
   "source": [
    "While we have a decent Precision score of 82%, we have very poor Recall and F1 scores, indicating that while the model is good at identifying a positive class, it is allowing many actual positive cases to fall through the cracks.\n",
    "\n",
    "Let's try our LogReg model and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce5ded5c-3ace-40b0-9902-08e56f9d8ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Precision: 0.5639097744360902\n",
      "LogReg Recall: 0.6550218340611353\n",
      "LogReg F1: 0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "logreg_pipe.fit(X_train['tweet_text'], y_train)\n",
    "\n",
    "y_val_pred_logreg = logreg_pipe.predict(X_val['tweet_text'])\n",
    "\n",
    "logreg_precision = precision_score(y_val, y_val_pred_logreg)\n",
    "logreg_recall = recall_score(y_val, y_val_pred_logreg)\n",
    "logreg_f1 = f1_score(y_val, y_val_pred_logreg)\n",
    "\n",
    "print(f'LogReg Precision: {logreg_precision}')\n",
    "print(f'LogReg Recall: {logreg_recall}')\n",
    "print(f'LogReg F1: {logreg_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfae29-9bd0-482f-9c2f-eca252ed4449",
   "metadata": {},
   "source": [
    "While our LogReg model did significant worse in terms of Precision, it did much better in terms of Recall and F1 scores, inducating less positive cases are falling through the cracks here, however it is mispredicting a good number of Positive cases that are not actually Positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c3c6c-9c79-4c26-918c-89c1f62cba07",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc1c8f-7322-4a6a-8acc-551448397fda",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0a9192e-5c04-4be1-88ea-0b955cb62d5b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a17859-b31c-4a11-b3ff-2925c41a8714",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65f8b1c2-2a02-40a8-8056-1eb6b54c66eb",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea12da3-8779-42fb-90af-071f28988c8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad3891c-86d8-413d-9ea8-3ffdaf56d745",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fc5d5-0254-4b68-bf14-bdae45eb8434",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6b276cb-d6d6-428f-ae78-4b69a2342d20",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf3ac8-cce6-4b68-a399-0de398b07465",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7983e4-4edd-4161-88e6-ba54d2d18d35",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
