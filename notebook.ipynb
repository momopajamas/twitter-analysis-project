{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2687fb5-e50c-4251-b9ed-9dec0f15b93b",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02274cc-a946-44ad-a54f-ae69201f6a23",
   "metadata": {},
   "source": [
    "Our company, Microsoft, wants to be able to factor in sentiments about our products that are expressed on social media platforms, namely X (formerly Twitter), where millions of users share positive, negative, or neutral sentiments about products they use in an organic way. While consumer or user reviews left through official platforms such as Yelp or Amazon are important to consider, the pool of users is rather limited as not everyone will go the extra mile to provide a review through those \"official\" channels, and taking more organic feedback expressed through platforms like X into consideration can provide us an extra layer of insight as to how the public is interacting with and perceiving our products. \n",
    "\n",
    "Specifically, Microsoft wants to be able to filter tweets carrying Positive sentiments towards our products or services so that we are able to assess what's working well and what areas can and should be developed further.\n",
    "\n",
    "The way we will go about this, is to create a **binary classifier model** that is trained and tested on a dataset containing tweets where users expressed various emotions or reactions to other products, as the essential issue is how well our model is able to parse through and differentiate between Positive tweets on the one hand, and Negative or Neutral tweets on the other hand.\n",
    "\n",
    "In evaluating the efficacy of our model, we need to ascertain how effective the model was at correctly identifying Positive tweets. Put differently, we need to keep an eye out for **False Positives**, since our model would cause many issues for us if it incorrectly pulled in Negative or Neutral tweets, which would complicate or muddy our analysis. While False Negatives are also something to consider, they are of less importance as missing out on Positive tweets would be less damaging to us as it is generally better to avoid overestimating Positive feedback anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb5bc9-31ed-4984-ae40-35746a6c927c",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e030c3-97d1-412e-aaf3-6420536c81c4",
   "metadata": {},
   "source": [
    "As this problem is about analyzing and categorizing sentiments expressed through text, we will need to build a model capable of Natural Language Processing, or NLP for short. This model needs to be adept at processing and parsing through text, and categorizing the text as 'Positive', 'Not Positive' (ie: 'Negative' or 'Neutral').\n",
    "\n",
    "We will engage in NLP to build a binary classifier that is capable of differentiating between 'Positive' and 'Negative' or 'Neutral' sentiments.\n",
    "\n",
    "### Dataset\n",
    "For these purposes, we will work with a [dataset we retrieved from data.world](https://data.world/crowdflower/brands-and-product-emotions) that contains more than 9,000 tweets expressing Positive, Negative, or Neutral sentiments towards Apple or Google products.\n",
    "\n",
    "The dataset contains information across three columns:\n",
    "1. `tweets_text`, which contains the text of the collected tweets themselves.\n",
    "2. `emotion_in_tweet_is_directed_at`, which indicates which product the tweet is speaking to. This column contains a number of values, however they all fall under either Apple of Google products (with the exception of a number of rows that contain 'No data').\n",
    "3. `is_there_an_emotion_directed_at_a_brand_or_product`, which categorizes the collected tweets according to either 'Positive emotion', 'Negative emotion', or 'No emotion toward brand or product'. There is a fourth category, 'I can't tell', which we need to investigate more before deciding whether or not to remove these entries.\n",
    "\n",
    "### Features and Labels\n",
    "The `tweets_text` column will serve as our features, or X, while `is_there_an_emotion_directed_at_a_brand_or_product` will serve as our labels, or y. \n",
    "\n",
    "To be more specific, we will use the `tweets_text` column to generate **TF-IDF (Term Frequency-Inverse Document Frequency)** scores, which assigns numeric values for key terms by weighing their frequency within a certain text against their frequency across different texts. This will help our model in gaining signals from significant words and reduce noise from frequent, insignificant words. These will be our features, at least in the initial baseline model.\n",
    "\n",
    "The second column, `emotion_in_tweet_is_directed_at`, is not relevant for our purposes, as our task is to build a model that can categorize the sentiments expressed, and not to determine *whom* the sentiments are addressing.\n",
    "\n",
    "### Class Imbalance\n",
    "Our labels have significant class imbalance, with Negative sentiments only comprising 6% of the data compared to 33% for Positive and 59% for Neutral. Since we are adding the Negative and Neutral tweets together in a single class, this gives us:\n",
    "- 33% Positive\n",
    "- 65% Not Positive\n",
    "  \n",
    "This will cause issues for us in both training the model and evaluating its performance according to success metrics.\n",
    "\n",
    "To compensate for this imbalance we will deploy **Class Weighting**, which is a strategy that can be used with certain models that gives higher importance to minority classes. \n",
    "\n",
    "### Success Metrics\n",
    "As described above, we need to pay extra mind to our model's ability to correctly identify Positive tweets, placing a higher importance on the rates of False Positives. However, we should also keep an eye on False Negatives to minimize the number of Positive tweets falling through the cracks.\n",
    "\n",
    "For this reason, we will rely on the following metrics:\n",
    "1. **Precision Score**, which evaluates how accurate we were in actually identifying Positive tweets (telling us the rates of False Positives). The higher the precision score, the lower the rate of False Positives. This will be our primary metric.\n",
    "2. **F1-Score**, which weighs the rate of False Positives and False Negatives, since we also want to minimize the rate at which we misclassify Positive tweets as Not Positive. This will be a seconadry metric for us.\n",
    "\n",
    "### Model Selection\n",
    "We will start with a simple baseline model as an initial performance check before moving on to more complex models. Since we have some class imbalance, we will deploy **Multinomial Naive Bayes (Multinomial NB)**, which can help compensate for this imbalance using a weighted approach. This model is also better at producing the metrics we outlined above. \n",
    "\n",
    "Multinomial NB will require us to compute **TF-IDF (Term Frequency-Inverse Document Frequency)**, as described above. However, this will have limited applicability on future application of the model, as future tweets will undoubtedly contain new slang and terms that arise and will not be computed in this current model.\n",
    "\n",
    "After establishing a baseline, we will then move on to testing out more complex models, namely **BERTweet (Bidirectional Encoder Representations from Transformers)**, a Deep Learning model which is well-suited for analyzing tweets in particular as it is trained on 850 million English tweets and can process special characters such as emojies, hashtags, etc., and is capable of determining contextual meaning from limited text as tweets had a limit of 140 characters back in 2013, which is when our dataset was compiled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efe8e8-ab0d-4f00-8798-2eaba8b4cebc",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89eddf1-3638-4ebe-ae5f-9d1aa36402e2",
   "metadata": {},
   "source": [
    "Since we want to first run a baseline MultinomialNB model, we will need to carry out several steps of Data Preparation in order for the data to be ready for modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d1bd21-842c-48e2-bbf1-2439879dc5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "                         AdamW\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "367e01e6-71fd-4fce-9d36-e29091832a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "# specifying the encoding as the file is a non-UTF-8 CSV file\n",
    "\n",
    "df = pd.read_csv(\"data/judge_tweet_product.csv\", encoding=\"latin-1\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac43546-a547-48d3-9d24-c53851c3ef04",
   "metadata": {},
   "source": [
    "As discussed earlier, the `emotion_in_tweet_is_directed_at` column is not necessary for our purposes of determining the sentiment of the tweet, so we will drop it from our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e7157d-b4a2-41b9-be0e-18a406b02386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the second column\n",
    "\n",
    "df = df.drop('emotion_in_tweet_is_directed_at', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c9a182-149c-4eb9-810d-00793708b9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if dropping column worked\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701163e-c760-4243-8806-8a4c89089b70",
   "metadata": {},
   "source": [
    "#### Now we need to check for any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c8c93a-3f98-4c2c-b93d-62c3e5f23f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                            1\n",
       "is_there_an_emotion_directed_at_a_brand_or_product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17aaf5d-fb97-4bf9-8c7f-1188b4ef1750",
   "metadata": {},
   "source": [
    "We have one row with null values. Let's take a look to see if we're able to simply drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ac85ca-5da7-45bd-b883-4271eefdf049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_text is_there_an_emotion_directed_at_a_brand_or_product\n",
       "6        NaN                 No emotion toward brand or product"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1999057-0ac3-4bc7-893c-6bc6b97b0a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                            0\n",
       "is_there_an_emotion_directed_at_a_brand_or_product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the row with null value\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# making sure it worked\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d13b2c-9c4a-47f1-834f-272dd204a6c7",
   "metadata": {},
   "source": [
    "#### Cleaning Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df21a52-60e1-4ec4-b815-5f8c217b0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02712e63-f200-437d-a2b8-66364c62ad91",
   "metadata": {},
   "source": [
    "There is a fourth category in our Target column, **'I can't tell'**, indicating that those who gathered this dataset were unsure about the sentiment expressed in about 2% of the tweets. \n",
    "\n",
    "Let's take a quick look. Since they only make up 2% of the dataset, it may be best to simply drop these entries and focus on our analysis on the Positive, Negative, and Neutral categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c2215a6-6bf8-4995-b51a-e2592d5c445a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Thanks to @mention for publishing the news of ...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ÛÏ@mention &amp;quot;Apple has opened a pop-up st...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Just what America needs. RT @mention Google to...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>The queue at the Apple Store in Austin is FOUR...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Hope it's better than wave RT @mention Buzz is...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020</th>\n",
       "      <td>It's funny watching a room full of people hold...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9032</th>\n",
       "      <td>@mention yeah, we have @mention , Google has n...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9037</th>\n",
       "      <td>@mention Yes, the Google presentation was not ...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>&amp;quot;Do you know what Apple is really good at...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9066</th>\n",
       "      <td>How much you want to bet Apple is disproportio...</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "90    Thanks to @mention for publishing the news of ...   \n",
       "102   ÛÏ@mention &quot;Apple has opened a pop-up st...   \n",
       "237   Just what America needs. RT @mention Google to...   \n",
       "341   The queue at the Apple Store in Austin is FOUR...   \n",
       "368   Hope it's better than wave RT @mention Buzz is...   \n",
       "...                                                 ...   \n",
       "9020  It's funny watching a room full of people hold...   \n",
       "9032  @mention yeah, we have @mention , Google has n...   \n",
       "9037  @mention Yes, the Google presentation was not ...   \n",
       "9058  &quot;Do you know what Apple is really good at...   \n",
       "9066  How much you want to bet Apple is disproportio...   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "90                                         I can't tell  \n",
       "102                                        I can't tell  \n",
       "237                                        I can't tell  \n",
       "341                                        I can't tell  \n",
       "368                                        I can't tell  \n",
       "...                                                 ...  \n",
       "9020                                       I can't tell  \n",
       "9032                                       I can't tell  \n",
       "9037                                       I can't tell  \n",
       "9058                                       I can't tell  \n",
       "9066                                       I can't tell  \n",
       "\n",
       "[156 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['is_there_an_emotion_directed_at_a_brand_or_product'] == \"I can't tell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb7f618-25e9-4abd-909a-45450bcb094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing \"I can't tell\" entries in the Target column from the dataframe\n",
    "\n",
    "df_clean = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] != \"I can't tell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db0243b-dc5e-4e16-bbf1-b0fb7c1bd66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8936 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[8936 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3825e565-9230-421f-8a9b-ba2bae883ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if it worked\n",
    "\n",
    "df_clean['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1982ad10-5b10-496e-8ec5-854c41d93675",
   "metadata": {},
   "source": [
    "Since our Target column contains three categories (\"Positive emotion, \"Negative emotion\", \"No emotion toward brand or product\"), and we'll need to collapse the latter two labels into a single category in order for us to conduct binary classification.\n",
    "\n",
    "We'll do this by converting the label values into 1s and 0s.\n",
    "- `1` meaning Positive\n",
    "- `0` meaning Not Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b8341d3-2cfa-4e3d-acf4-655f26b5b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping 1s and 0s onto the Target column values\n",
    "\n",
    "df_clean.loc[:,'is_there_an_emotion_directed_at_a_brand_or_product'] = df['is_there_an_emotion_directed_at_a_brand_or_product'].map({\n",
    "    'Positive emotion': 1,\n",
    "    'Negative emotion': 0,\n",
    "    'No emotion toward brand or product': 0\n",
    "})\n",
    "\n",
    "# converting binary values into integers\n",
    "\n",
    "df_clean.loc[:,'is_there_an_emotion_directed_at_a_brand_or_product'] = \\\n",
    "df_clean['is_there_an_emotion_directed_at_a_brand_or_product'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6440953-d1d4-4041-ad00-d4a29ffab5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure it worked\n",
    "\n",
    "df_clean['is_there_an_emotion_directed_at_a_brand_or_product'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a017a6-4e8b-4b75-81b5-a185a18903fe",
   "metadata": {},
   "source": [
    "For convenience, we'll change the name of our Target column to something shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03378338-96fc-441e-868f-ba47b45c5f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text is_positive\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...           0\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...           1\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...           1\n",
       "3  @sxsw I hope this year's festival isn't as cra...           0\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...           1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df_clean.rename(columns={'is_there_an_emotion_directed_at_a_brand_or_product': 'is_positive'})\n",
    "\n",
    "# checking if it worked\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee337b-2385-4021-92be-5145e0feea93",
   "metadata": {},
   "source": [
    "#### Train-Test-Splitting\n",
    "Now that our dataset is cleaned, we'll split the data into training and test sets before preprocessing the text data in order to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fd8a2c7-ac4b-45c5-894f-3886395ff72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting X (Features) and y (Target)\n",
    "\n",
    "X = df_clean[['tweet_text']]\n",
    "y = df_clean['is_positive']\n",
    "\n",
    "# splitting the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba307d0-f56e-4771-98ec-068e9fc93118",
   "metadata": {},
   "source": [
    "#### Creating Custom Transformers and Pipelines\n",
    "##### **Baseline Model**\n",
    "\n",
    "We can now start preparing our X variable (features) for our modeling.\n",
    "\n",
    "We'll need to convert all words to lowercase, remove special characters, remove stop words, tokenize the text and apply lemmatization in order for our text to be processed uniformly across all variations of the same words.\n",
    "\n",
    "These steps can be built into our Pipeline, which we will deploy to prevent data leakage.\n",
    "\n",
    "First, we need to create a **custom transformer** to carry out these steps, before creating the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "248c59e1-f37c-493d-9e2c-1e4e969d5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining custom transformer with parameters that allow it to work like an sklearn transformer inside the pipelines\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This custom transformer will\n",
    "    1) Lower case the text,\n",
    "    2) Remove special characters,\n",
    "    3) Tokenize the text,\n",
    "    4) Lemmatize the text\n",
    "    \"\"\"\n",
    "    # initializing Lemmatizer for later use\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # fitting the transformer\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    # transforming the text, creating list to store preprocessed words\n",
    "    def transform(self, X):\n",
    "        preprocessed_words = []\n",
    "\n",
    "        # for loop to transform all words in the text\n",
    "        for word in X:\n",
    "            \n",
    "            word = word.lower() # lowercasing the words\n",
    "            \n",
    "            word = re.sub(r'[^a-z\\s]', '', word) # removing special characters\n",
    "            \n",
    "            tokens = nltk.word_tokenize(word) # tokenizing words\n",
    "            \n",
    "            lemmatized_words = ' '.join([self.lemmatizer.lemmatize(word) for word in tokens]) # lemmatizing the tokens \\\n",
    "                                                                                              # into a list of strings\n",
    "            \n",
    "            preprocessed_words.append(lemmatized_words) # adding preprocessed words back to the list\n",
    "            \n",
    "        return preprocessed_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c9669-72dc-414c-b86d-8abc72ffd7ec",
   "metadata": {},
   "source": [
    "Now that we have our custom function ready, we can prepare a Pipeline for our baseline MultinomialNB model. \n",
    "\n",
    "This Pipeline will cover the following steps:\n",
    "1. Run the Custom Transformer we just created.\n",
    "2. Vectorize the text into TF-IDF features.\n",
    "3. Run a MultinomialNB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c35d616-e0ac-4145-805c-716b9b0e908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Pipeline for MultinomialNB modeling\n",
    "\n",
    "baseline_pipe = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()), # preprocessing transformer\n",
    "    ('vectorizer', TfidfVectorizer()), # Convert to TF-IDF features\n",
    "    ('classifier', MultinomialNB()), # Run the MultinomialNB model\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d50db-40e8-4286-acef-57b345ec28fa",
   "metadata": {},
   "source": [
    "##### **BERTweet Model**\n",
    "Next, we need to prepare a Pipeline for our BERTweet model, which is a more advanced model that we will use after establishing a baseline.\n",
    "\n",
    "As discussed above, BERTweet is a more advanced, pre-trained model that is adept at handling tweets specifically, and preprocessing text for this model is different than for other types of models. Since the model has its own tokenizer, we need to keep the text as raw as possible and don't need to tokenize, remove special characters, lemmatize or stem the text, or lowercase the text.\n",
    "\n",
    "First, we need to create two Custom Transformers tailored for our BERTweet model:\n",
    "1. Tokenizer Transformer\n",
    "2. Classifier Transformer\n",
    "\n",
    "Since BERTweet is a deep learning model, we will need to integrate **PyTorch Tensors** into our preprocessing transformers, as they are multi-dimensional arrays similar to NumPy arrays but more are optmized for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d01fc04d-74ed-4a06-ac86-2de62ea07483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Custom Tokenizer Transformer for BERTweet\n",
    "\n",
    "class BERTTokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name=\"bert-base-uncased\", max_length=128):\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, use_fast=True)\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.__call__(X)\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        if not isinstance(texts, list):\n",
    "            texts = [texts]\n",
    "    \n",
    "        return self.tokenizer(\n",
    "            text=texts,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c044b083-a789-4965-9583-cd2d1bf61e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Custom Classifier Transformer for BERTweet\n",
    "\n",
    "class BERTClassifier(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Custom Classifier specifically tailored for BERTweet sentiment analysis\n",
    "    1) load pretrained BERTweet model\n",
    "    2) run inference without training (training is not required)\n",
    "    3) convert model outputs into our class labels ('Positive' or 'Not Positive')\n",
    "    4) retun probabilities or confidence scores for our predicted classifications\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name = \"bert-base-uncased\", num_labels = 2, device = None):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "        self.device = torch.device(('mps' if torch.has_mps else 'cpu'), dtype=torch.float16) if device is None else device\n",
    "        self.model.to(self.device, dtype=torch.float16)\n",
    "        self.model.eval() # setting the model to evaluate\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self # pretrained model, so no training needed\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        use tokenized inputs to generate sentiment classification predictions\n",
    "        \"\"\"\n",
    "        with torch.no_grad(): # disabling gradient calculation for quicker inference\n",
    "            outputs = self.model(**X) # passing tokenized inputs into BERT model\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy() # converting predictions to NumPy\n",
    "        return preds # returning classification labels\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        finding prediction probabilities\n",
    "        \"\"\"\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = self.model(**X)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        return probs # returning classification probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18254264-f479-4e95-a9e8-2181b18bbe6e",
   "metadata": {},
   "source": [
    "The model we invoked in the transformers above, `'bert-base-uncased'`, requires fine-tuning on data before it can successfully be deployed in a Pipeline.\n",
    "\n",
    "We'll also need to create validation sets for this portion, and then convert the sets into a `Hugging Face` format in order to be compatible with the trainer we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "982f77eb-1efb-4f91-98b5-0b0a72b046f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training sets into training and validation sets\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e4a7469-ec41-40d8-850a-50b9d76f21ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating copies of training and validation sets to keep originals for baseline model\n",
    "\n",
    "X_train_copy, y_train_copy = X_train.copy(), y_train.copy()\n",
    "X_val_copy, y_val_copy = X_val.copy(), y_val.copy()\n",
    "\n",
    "X_train_copy, y_train_copy = X_train_copy.reset_index(drop=True), y_train_copy.reset_index(drop=True)\n",
    "X_val_copy, y_val_copy = X_val_copy.reset_index(drop=True), y_val_copy.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d2f34b7-79ad-44fa-8c0d-d4eb221a52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    creating a custom transformer to tokenize text \n",
    "    and convert into PyTorch tensors\n",
    "    \"\"\"\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        # Ensure texts is a list of strings, not a list of lists\n",
    "        self.texts = [str(text) for text in (texts.tolist() if hasattr(texts, \"tolist\") else texts)]\n",
    "        self.labels = labels.tolist() if hasattr(labels, \"tolist\") else labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, list):  # Handling batch sampling\n",
    "            texts = [self.texts[i] for i in idx]\n",
    "            labels = [self.labels[i] for i in idx]\n",
    "        else:\n",
    "            texts = [self.texts[idx]]\n",
    "            labels = [self.labels[idx]]\n",
    "    \n",
    "        tokenized = self.tokenizer.transform(texts)\n",
    "    \n",
    "        return {\n",
    "            \"input_ids\": tokenized[\"input_ids\"],  \n",
    "            \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edcc9510-18ae-4a5e-b6ca-dde1b2aed1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a83993faa4a4c978acea8159f2ec6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e679b886d6f46709ab93fd6063d9946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e93261bd11b4eb58677bc94949409d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11e4973dbad422bb9d9cb326d771d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BERTTokenizer()\n",
    "\n",
    "# converting lists to PyTorch datasets\n",
    "train_dataset = PTDataset(\n",
    "    X_train_copy.squeeze().tolist(),\n",
    "    y_train_copy.tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = PTDataset(\n",
    "    X_val_copy.squeeze().tolist(),\n",
    "    y_val_copy.tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "# creating PyTorch DataLoaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True # training should be randomized so shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False # no need to shuffle validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57bbfba3-1425-4aa1-8cc1-4a1001f46ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e75c8a2b694339867e56233eca6e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# manually fine-tuning the 'bert-base-uncased' model using PyTorch\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained( # loading the model\n",
    "    'bert-base-uncased', \n",
    "    num_labels=2\n",
    ") \n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_built() else 'cpu') # optimizing for Apple Metal hardware\n",
    "model.to(device, dtype=torch.float16)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5) # defining the optimizer\n",
    "\n",
    "# defining the loss function\n",
    "class_weights = torch.tensor([1.0, 3.0], device=device)  # adjust the weight of positive class\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484e9d1-c1ff-41ce-95bd-3fbcb042a17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|                                                                                                                                      | 0/1341 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(\n",
    "        train_dataloader, \n",
    "        desc=f'Epoch {e+1}/{epochs}'\n",
    "    )    \n",
    "\n",
    "    for batch in loop:\n",
    "        batch = {key: val.to(device) for key, val in batch.items()} # moving batch to new device\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = criterion(outputs.logits, batch['labels'])\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch {e+1} - Average Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "print('Training Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99939b5-e30b-4e87-aa45-2f7807d94393",
   "metadata": {},
   "source": [
    "Now that we have run the training loop on our training dataset, we need to evaluate the model's performance on a validation dataset in order to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3a24544b-431a-4ae8-be77-203ddcb96981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6557, Accuracy: 0.6401\n",
      "Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # setting to evaluation mode\n",
    "y_true = []\n",
    "y_pred = []\n",
    "total_loss = 0\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for batch in val_dataloader:\n",
    "        batch = {key: val.to(device) for key, val in batch.items()}  \n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = criterion(outputs.logits, batch['labels'])\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        y_true.extend(batch['labels'].cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "avg_val_loss = total_loss / len(val_dataloader)\n",
    "\n",
    "# Compute Precision, Recall, F1 Score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = np.sum(np.array(y_pred) == np.array(y_true)) / len(y_true)\n",
    "\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b086fe-0a1c-461b-89f9-cbbda585534a",
   "metadata": {},
   "source": [
    "With our custom transformers made, we can go ahead and create our BERT Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92ce062a-55b0-4fbd-ae6a-cb820f0fcacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# creating pipeline for BERTweet model\n",
    "\n",
    "bert_pipe = Pipeline([\n",
    "    ('tokenizer', BERTTokenizer()),\n",
    "    ('classifier', BERTClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42caff9e-aefe-42ea-8d97-35c1c914baaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"vinai/bertweet-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4633dedf-c980-488e-9069-c43250aac75b",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb584cb-ea50-4ce1-bae0-11c745da7728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "192091fc-324a-421a-b17b-e27fbbef6c41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ded5c-3ace-40b0-9902-08e56f9d8ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0a9192e-5c04-4be1-88ea-0b955cb62d5b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a17859-b31c-4a11-b3ff-2925c41a8714",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65f8b1c2-2a02-40a8-8056-1eb6b54c66eb",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea12da3-8779-42fb-90af-071f28988c8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad3891c-86d8-413d-9ea8-3ffdaf56d745",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fc5d5-0254-4b68-bf14-bdae45eb8434",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6b276cb-d6d6-428f-ae78-4b69a2342d20",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf3ac8-cce6-4b68-a399-0de398b07465",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7983e4-4edd-4161-88e6-ba54d2d18d35",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
